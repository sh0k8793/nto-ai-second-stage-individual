{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":13710760,"sourceType":"datasetVersion","datasetId":8722327}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom tqdm.auto import tqdm\nimport warnings\n\nwarnings.filterwarnings('ignore')\ntqdm.pandas()\n\nDATA_PATH = '/kaggle/input/nto-ai-second-stage-individual/' # –£–∫–∞–∂–∏—Ç–µ –ø—É—Ç—å –∫ –≤–∞—à–∏–º –¥–∞–Ω–Ω—ã–º\nRANDOM_STATE = 42","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"–ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö —Ñ–∞–π–ª–æ–≤\")\ntrain_df = pd.read_csv(f'{DATA_PATH}train.csv', sep=',')\ntest_df = pd.read_csv(f'{DATA_PATH}test.csv', sep=',')\nusers_df = pd.read_csv(f'{DATA_PATH}users.csv', sep=',')\nbook_genres_df = pd.read_csv(f'{DATA_PATH}book_genres.csv', sep=',')\n\nbooks_df = pd.read_csv(f'{DATA_PATH}books.csv', sep=',', engine='python', encoding='utf-8-sig', on_bad_lines='skip')\nbook_descriptions_df = pd.read_csv(f'{DATA_PATH}book_descriptions.csv', sep=',', engine='python', encoding='utf-8-sig', on_bad_lines='skip')\n\nfor df in [train_df, test_df, users_df, books_df, book_genres_df, book_descriptions_df]:\n    df.columns = df.columns.str.strip()\n\ntrain_df['timestamp'] = pd.to_datetime(train_df['timestamp'])\n\nprint(\"\\n–î–∞–Ω–Ω—ã–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã\")\nprint(\"\\n–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–ª–æ–Ω–æ–∫ –≤ books_df:\")\nprint(list(books_df.columns))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"–û–±—ä–µ–¥–∏–Ω–µ–Ω–∏–µ —Ç–∞–±–ª–∏—Ü\")\n\ntrain_df = train_df.merge(users_df, on='user_id', how='left')\ntrain_df = train_df.merge(books_df, on='book_id', how='left')\n\ntest_df = test_df.merge(users_df, on='user_id', how='left')\ntest_df = test_df.merge(books_df, on='book_id', how='left')\n\nprint(\"\\n–î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –æ–±—ä–µ–¥–∏–Ω–µ–Ω—ã\")\ntrain_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_read_df = train_df[train_df['has_read'] == 1].copy()\ntrain_read_df = train_read_df.sort_values('timestamp').reset_index(drop=True)\n\nprint(f\"–í—Å–µ–≥–æ –æ—Ü–µ–Ω–æ–∫ –≤ —Ç—Ä–µ–π–Ω–µ: {len(train_read_df)}\")\n\nsplit_index = int(len(train_read_df) * 0.9)\ntrain_part = train_read_df.iloc[:split_index]\nval_part = train_read_df.iloc[split_index:]\n\nprint(f\"–†–∞–∑–º–µ—Ä –æ–±—É—á–∞—é—â–µ–π —á–∞—Å—Ç–∏: {len(train_part)}\")\nprint(f\"–†–∞–∑–º–µ—Ä –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π —á–∞—Å—Ç–∏: {len(val_part)}\")\n\nassert train_part['timestamp'].max() < val_part['timestamp'].min()\nprint(\"–í—Ä–µ–º–µ–Ω–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def create_features(df, train_data):\n    result_df = df.copy()\n\n    global_mean_rating = train_data['rating'].mean()\n\n    user_stats = train_data.groupby('user_id')['rating'].agg(['mean', 'count', 'std']).reset_index()\n    user_stats.columns = ['user_id', 'user_mean_rating', 'user_ratings_count', 'user_std_rating']\n    \n    result_df = result_df.merge(user_stats, on='user_id', how='left')\n\n    item_stats = train_data.groupby('book_id')['rating'].agg(['mean', 'count', 'std']).reset_index()\n    item_stats.columns = ['book_id', 'book_mean_rating', 'book_ratings_count', 'book_std_rating']\n    \n    result_df = result_df.merge(item_stats, on='book_id', how='left')\n\n    result_df['user_rating_diff'] = result_df['user_mean_rating'] - global_mean_rating\n    result_df['book_rating_diff'] = result_df['book_mean_rating'] - global_mean_rating\n\n    result_df.fillna(global_mean_rating, inplace=True)\n    \n    return result_df\n\ntrain_featured = create_features(train_part, train_part)\nval_featured = create_features(val_part, train_part)\ntest_featured = create_features(test_df, train_read_df)\n\nprint(\"–ü—Ä–∏–∑–Ω–∞–∫–∏ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω—ã.\")\ndisplay(train_featured.head())","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"features = [\n    'age', 'gender', 'publication_year', 'avg_rating',\n    'user_mean_rating', 'user_ratings_count', 'user_std_rating',\n    'book_mean_rating', 'book_ratings_count', 'book_std_rating',\n    'user_rating_diff', 'book_rating_diff'\n]\ntarget = 'rating'\n\nX_train = train_featured[features]\ny_train = train_featured[target]\nX_val = val_featured[features]\ny_val = val_featured[target]\n\nlgb_params = {\n    'objective': 'regression_l1', \n    'metric': 'rmse',\n    'n_estimators': 2000,\n    'learning_rate': 0.06,\n    'feature_fraction': 0.8,\n    'bagging_fraction': 0.8,\n    'bagging_freq': 1,\n    'lambda_l1': 1,\n    'lambda_l2': 1,\n    'num_leaves': 31,\n    'verbose': -1,\n    'n_jobs': -1,\n    'seed': RANDOM_STATE,\n    'boosting_type': 'gbdt',\n}\n\nmodel = lgb.LGBMRegressor(**lgb_params)\n\nmodel.fit(X_train, y_train,\n          eval_set=[(X_val, y_val)],\n          eval_metric='rmse',\n          callbacks=[lgb.early_stopping(100, verbose=True)])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport lightgbm as lgb\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom tqdm.auto import tqdm\nimport random\n\n# --- –ù–ê–°–¢–†–û–ô–ö–ò ---\nTARGET_RMSE = 2.68781\nTARGET_MAE = 1.89   # (–î–ª—è —Å–ø—Ä–∞–≤–∫–∏, —Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å –±—É–¥–µ–º –ø–æ RMSE –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç—Ä–∏–∫–µ)\nDESIRED_SEEDS_COUNT = 50 \nMAX_ATTEMPTS = 10000       # –ó–∞—â–∏—Ç–∞ –æ—Ç –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ–≥–æ —Ü–∏–∫–ª–∞ (–µ—Å–ª–∏ 42 –±—ã–ª —Å–ª–∏—à–∫–æ–º —Ö–æ—Ä–æ—à)\n\nlgb_params_base = {\n    'objective': 'regression_l1', \n    'metric': 'rmse',\n    'n_estimators': 3000,\n    'learning_rate': 0.06,\n    'feature_fraction': 0.8,\n    'bagging_fraction': 0.8,\n    'bagging_freq': 1,\n    'lambda_l1': 1,\n    'lambda_l2': 1,\n    'num_leaves': 31,\n    'verbose': -1,\n    'n_jobs': -1,\n    'seed': RANDOM_STATE,\n    'boosting_type': 'gbdt',\n}\n\n# --- –•—Ä–∞–Ω–∏–ª–∏—â–∞ ---\ngood_seeds = []\ntest_preds_accum = np.zeros(len(test_featured))\nval_preds_accum = np.zeros(len(X_val))\n\nprint(f\"üé∞ –ó–ê–ü–£–°–ö–ê–ï–ú –ö–ê–ó–ò–ù–û! –¶–µ–ª—å: –Ω–∞–π—Ç–∏ {DESIRED_SEEDS_COUNT} —Å–∏–¥–æ–≤ —Å RMSE < {TARGET_RMSE}\")\n\npbar = tqdm(total=DESIRED_SEEDS_COUNT)\nattempts = 0\n\nwhile len(good_seeds) < DESIRED_SEEDS_COUNT and attempts < MAX_ATTEMPTS:\n    attempts += 1\n\n    current_seed = np.random.randint(1, 100000)\n    if current_seed == 42 or current_seed in good_seeds:\n        continue\n\n    params = lgb_params_base.copy()\n    params['random_state'] = current_seed\n    \n    model = lgb.LGBMRegressor(**params)\n    \n    model.fit(\n        X_train, y_train,\n        eval_set=[(X_val, y_val)],\n        eval_metric='rmse',\n        callbacks=[lgb.early_stopping(100, verbose=False)]\n    )\n\n    val_pred = model.predict(X_val)\n    val_pred = np.clip(val_pred, 0, 10)\n    rmse = np.sqrt(mean_squared_error(y_val, val_pred))\n\n    if rmse < TARGET_RMSE:\n        print(f\"üíé –ù–ê–ô–î–ï–ù –ê–õ–ú–ê–ó! Seed: {current_seed} | RMSE: {rmse:.5f} (Better by {TARGET_RMSE - rmse:.5f})\")\n\n        t_pred = model.predict(test_featured[features])\n        t_pred = np.clip(t_pred, 0, 10)\n        \n        test_preds_accum += t_pred\n        val_preds_accum += val_pred\n        good_seeds.append(current_seed)\n        pbar.update(1)\n    else:\n        if attempts % 10 == 0:\n            print(f\"Attempt {attempts}: Seed {current_seed} gave RMSE {rmse:.5f} (Too bad)\")\n\npbar.close()\n\n# --- –§–ò–ù–ê–õ ---\nif len(good_seeds) > 0:\n    print(f\"\\n‚úÖ –°–æ–±—Ä–∞–Ω–æ {len(good_seeds)} —Å–∏–¥–æ–≤: {good_seeds}\")\n    \n    # –£—Å—Ä–µ–¥–Ω—è–µ–º\n    final_test_preds = test_preds_accum / len(good_seeds)\n    final_val_preds = val_preds_accum / len(good_seeds)\n    \n    # –ß–µ–∫ –º–µ—Ç—Ä–∏–∫–∏ –∞–Ω—Å–∞–º–±–ª—è\n    ensemble_rmse = np.sqrt(mean_squared_error(y_val, final_val_preds))\n    print(f\"\\nüèÜ RMSE –ê–ù–°–ê–ú–ë–õ–Ø: {ensemble_rmse:.5f}\")\n    if ensemble_rmse < TARGET_RMSE:\n        print(f\"üöÄ –ü–†–û–ë–û–ô! –ê–Ω—Å–∞–º–±–ª—å –ª—É—á—à–µ –æ–¥–∏–Ω–æ—á–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ {TARGET_RMSE - ensemble_rmse:.5f}\")\n    else:\n        print(\"ü§î –ê–Ω—Å–∞–º–±–ª—å –Ω–µ –ø–æ–±–∏–ª –ª—É—á—à—É—é –æ–¥–∏–Ω–æ—á–Ω—É—é (–±—ã–≤–∞–µ—Ç, –µ—Å–ª–∏ —Å–∏–¥—ã —Å–ª–∏—à–∫–æ–º –∫–æ—Ä—Ä–µ–ª–∏—Ä—É—é—Ç)\")\n\n    # –°–∞–±–º–∏—Ç\n    submission = pd.DataFrame({\n        'user_id': test_df['user_id'],\n        'book_id': test_df['book_id'],\n        'rating_predict': final_test_preds\n    })\n    \n    filename = 'submission_casino_royale_final_pupupu.csv'\n    submission.to_csv(filename, index=False)\n    print(f\"–§–∞–π–ª {filename} –≥–æ—Ç–æ–≤.\")\n    \nelse:\n    print(\"‚ùå –ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ —Å–∏–¥–∞ –ª—É—á—à–µ 42. –ü–æ–ø—Ä–æ–±—É–π —Å–º—è–≥—á–∏—Ç—å —É—Å–ª–æ–≤–∏–µ –∏–ª–∏ —É–≤–µ–ª–∏—á—å learning_rate.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(12, 8))\n\nlgb.plot_importance(model, max_num_features=20, importance_type='gain', figsize=(12, 8), title='Feature Importance (Gain)')\nplt.show()\n\nlgb.plot_importance(model, max_num_features=20, importance_type='split', figsize=(12, 8), title='Feature Importance (Split)')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"val_preds = model.predict(X_val)\n\nval_preds = np.clip(val_preds, 0, 10)\n\nrmse = np.sqrt(mean_squared_error(y_val, val_preds))\nmae = mean_absolute_error(y_val, val_preds)\n\nprint(f\"–õ–æ–∫–∞–ª—å–Ω–∞—è –≤–∞–ª–∏–¥–∞—Ü–∏—è:\")\nprint(f\"RMSE: {rmse:.4f}\")\nprint(f\"MAE: {mae:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(\"–û–±—É—á–µ–Ω–∏–µ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –º–æ–¥–µ–ª–∏ –Ω–∞ –≤—Å–µ—Ö –¥–∞–Ω–Ω—ã—Ö\")\n\nX_full = pd.concat([train_featured[features], val_featured[features]])\ny_full = pd.concat([train_featured[target], val_featured[target]])\n\nbest_iteration = model.best_iteration_\nif best_iteration is None:\n    best_iteration = lgb_params['n_estimators']\n    \nlgb_params['n_estimators'] = best_iteration\n\nfinal_model = lgb.LGBMRegressor(**lgb_params)\nfinal_model.fit(X_full, y_full)\n\nprint(\"–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö...\")\nX_test = test_featured[features]\ntest_preds = final_model.predict(X_test)\n\ntest_preds = np.clip(test_preds, 0, 10)\n\nsubmission_df = pd.DataFrame({\n    'user_id': test_df['user_id'],\n    'book_id': test_df['book_id'],\n    'rating_predict': test_preds\n})\n\nsubmission_df.to_csv('submission_final_pupupu.csv', index=False, sep=',')\nprint(\"–§–∞–π–ª submission.csv —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω.\")\ndisplay(submission_df.head())","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}